name: All-In-One Offset Extractor

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  build-and-extract:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up .NET SDK
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '8.0.x'

      - name: Build Il2CppDumper from Source
        run: |
          git clone https://github.com/Perfare/Il2CppDumper.git
          cd Il2CppDumper
          dotnet publish -c Release -f net8.0 -r linux-x64 --self-contained true /p:PublishSingleFile=true
          find bin/Release/net8.0/linux-x64/publish/ -type f -executable -exec cp {} ../Il2CppDumper \;
          cd ..
          chmod +x Il2CppDumper
          echo "[+] Dumper is ready."

      - name: Run Il2CppDumper
        run: |
          if [ -f "libil2cpp.so" ] && [ -f "global-metadata.dat" ]; then
            ./Il2CppDumper libil2cpp.so global-metadata.dat .
          else
            echo "[-] Error: libil2cpp.so or global-metadata.dat not found!"
            exit 1
          fi
        continue-on-error: true

      - name: Extract Offsets using Inline Python
        shell: python
        run: |
          import os, re, json, gzip
          
          dump_file = "dump.cs"
          output_zip = "offsets.json.gz"
          
          if os.path.exists(dump_file):
              print("[+] Starting inline extraction...")
              # نمط البحث عن العناوين والأسماء
              pattern = re.compile(r"// RVA: (0x[A-F0-9]+).*?\n\s+.*? ([\w_<>]+)\(")
              extracted_data = {}
              
              with open(dump_file, "r", encoding="utf-8") as f:
                  content = f.read()
                  for match in pattern.finditer(content):
                      address, name = match.groups()
                      extracted_data[name] = address
              
              # حفظ وضغط البيانات
              compact_json = json.dumps(extracted_data, separators=(',', ':')).encode('utf-8')
              with gzip.open(output_zip, 'wb') as f:
                  f.write(compact_json)
              
              print(f"[+] Extraction done! Found {len(extracted_data)} methods.")
          else:
              print("[-] dump.cs was not generated.")

      - name: Cleanup and Upload
        run: |
          # حذف كل الملفات الكبيرة قبل الرفع
          rm -rf Il2CppDumper/
          rm -f Il2CppDumper dump.cs dummy.dll script.py
          
      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: Full-Game-Offsets
          path: offsets.json.gz
          retention-days: 2